from typing import List, Tuple

from open_alpha_tensor.root_op import TrainAlphaTensorRootOp


def train_alpha_tensor(
    tensor_length: int,
    input_size: int,
    scalars_size: int,
    emb_dim: int,
    n_steps: int,
    n_logits: int,
    n_samples: int,
    optimizer_name: str,
    lr: float,
    lr_decay_factor: float,
    lr_decay_steps: int,
    weight_decay: float,
    loss_params: Tuple[float, float],
    checkpoint_dir: str,
    epochs: int,
    batch_size: int,
    len_data: int,
    n_synth_data: int,
    pct_synth: float,
    limit_rank: int,
    n_actors: int,
    mc_n_sim: int,
    N_bar: int,
    device: str,
    save_dir: str,
    random_seed: int,
    n_cob: int,
    cob_prob: float,
    data_augmentation: bool,
    extra_devices: List[str],
):
    root_op = TrainAlphaTensorRootOp()
    root_op.execute(
        tensor_length=tensor_length,
        input_size=input_size,
        scalars_size=scalars_size,
        emb_dim=emb_dim,
        n_steps=n_steps,
        n_logits=n_logits,
        n_samples=n_samples,
        optimizer_name=optimizer_name,
        lr=lr,
        lr_decay_factor=lr_decay_factor,
        lr_decay_steps=lr_decay_steps,
        weight_decay=weight_decay,
        loss_params=loss_params,
        checkpoint_dir=checkpoint_dir,
        epochs=epochs,
        batch_size=batch_size,
        len_data=len_data,
        n_synth_data=n_synth_data,
        pct_synth=pct_synth,
        limit_rank=limit_rank,
        n_actors=n_actors,
        mc_n_sim=mc_n_sim,
        N_bar=N_bar,
        device=device,
        save_dir=save_dir,
        random_seed=random_seed,
        n_cob=n_cob,
        cob_prob=cob_prob,
        data_augmentation=data_augmentation,
        extra_devices=extra_devices,
    )
    return root_op.get_result()
