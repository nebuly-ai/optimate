{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c977e4a",
      "metadata": {
        "id": "3c977e4a"
      },
      "source": [
        "![nebullvm nebuly AI accelerate inference optimize DeepLearning](https://user-images.githubusercontent.com/38586138/201391643-a80407e5-2c28-409c-90c9-327795cd27e8.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6240f0ea",
      "metadata": {
        "id": "6240f0ea"
      },
      "source": [
        "# Accelerate PyTorch YOLO with Speedster\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cfcd562",
      "metadata": {
        "id": "6cfcd562"
      },
      "source": [
        "Hi and welcome ðŸ‘‹\n",
        "\n",
        "In this notebook we will discover how in just a few steps you can speed up the response time of deep learning model inference using the Speedster app from the open-source library nebullvm.\n",
        "\n",
        "With Speedster's latest API, you can speed up models up to 10 times without any loss of accuracy (option A), or accelerate them up to 20-30 times by setting a self-defined amount of accuracy/precision that you are willing to trade off to get even lower response time (option B). To accelerate your model, Speedster takes advantage of various optimization techniques such as deep learning compilers (in both option A and option B), quantization, half accuracy, and so on (option B).\n",
        "\n",
        "Let's jump to the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38171e92",
      "metadata": {},
      "outputs": [],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "okgu97ThVwnH",
      "metadata": {
        "id": "okgu97ThVwnH"
      },
      "source": [
        "### Install Speedster"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48aljCHu14-H",
      "metadata": {
        "id": "48aljCHu14-H"
      },
      "source": [
        "Install Speedster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QFQh3BVr1-GO",
      "metadata": {
        "id": "QFQh3BVr1-GO"
      },
      "outputs": [],
      "source": [
        "!pip install speedster"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a7a86b3",
      "metadata": {
        "id": "8a7a86b3"
      },
      "source": [
        "Install deep learning compilers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffbfa32",
      "metadata": {
        "id": "cffbfa32"
      },
      "outputs": [],
      "source": [
        "!python -m nebullvm.installers.auto_installer  --backends torch-full --compilers all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62f5afa",
      "metadata": {
        "id": "e62f5afa"
      },
      "source": [
        "### Install and test YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38d727d",
      "metadata": {
        "id": "b38d727d"
      },
      "source": [
        "Let's install YOLO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48f6a35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f48f6a35",
        "outputId": "5b06307a-9196-4e5e-a542-1254d6c94ce2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "! pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "92f49833",
      "metadata": {
        "id": "92f49833"
      },
      "source": [
        "We start by downloading the model from the Torch hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc46f67",
      "metadata": {
        "id": "2dc46f67"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "import types\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead6637d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248,
          "referenced_widgets": [
            "7f41159d22fe4ce7b8e7789a92478242",
            "2ecf6a6cfad64af698a88479ba95005b",
            "e7a2646ac0cd4afba67823799147ce13",
            "fd77306783b84b489b90d072a44a27d8",
            "94a4bc5454074b5c900186a60a950d19",
            "682cafb37aa34c75961d61d2665a50b7",
            "5e71284dc02f4346b217732643c90b86",
            "881f619ee75547a49c6d48fd3140721c",
            "56a1b99b282a4a63a64f48347963a5ab",
            "a59557bb103e4a3b96062c60d539db35",
            "65786546f69b420b9ec8451c97338f30"
          ]
        },
        "id": "ead6637d",
        "outputId": "8d44d380-535d-446c-fcb0-bb55ba9e9f84"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=True)\n",
        "\n",
        "# Images\n",
        "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KcteQ5tsWy1v",
      "metadata": {
        "id": "KcteQ5tsWy1v"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d07ab0",
      "metadata": {
        "id": "37d07ab0"
      },
      "source": [
        "## Optimization with Speedster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f9f650",
      "metadata": {
        "id": "74f9f650"
      },
      "outputs": [],
      "source": [
        "from speedster import optimize_model, save_model, load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "147a42b9",
      "metadata": {
        "id": "147a42b9"
      },
      "source": [
        "First, we need to slightly modify YOLO's forward method. \n",
        "\n",
        "The last layer of the YOLOv5 implementation can create problems on certain hardware for some deep learning compilers that run on the Speedster core. Since Speedster aims to be hardware agnostic, we circumvent any potential obstacles by splitting the network body from the head (the last layer) and optimizing only the body."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56cfaf99",
      "metadata": {
        "id": "56cfaf99"
      },
      "outputs": [],
      "source": [
        "core_model = copy.deepcopy(model.model.model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9c8882",
      "metadata": {
        "id": "4f9c8882"
      },
      "outputs": [],
      "source": [
        "def _forward_once(self, x, profile=False, visualize=False):\n",
        "    y, dt = [], []  # outputs\n",
        "    for m in self.model:\n",
        "        if m.f != -1:  # if not from previous layer\n",
        "            x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
        "        if profile:\n",
        "            self._profile_one_layer(m, x, dt)\n",
        "        x = m(x)  # run\n",
        "        y.append(x if m.i in self.save else None)  # save output\n",
        "        if visualize:\n",
        "            feature_visualization(x, m.type, m.i, save_dir=visualize)\n",
        "    self.last_y = y\n",
        "    return x\n",
        "core_model._forward_once = types.MethodType(_forward_once, core_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2197ca91",
      "metadata": {
        "id": "2197ca91"
      },
      "source": [
        "The reimplementation of the forward method is needed since we need to store the ys for giving to the head the right tensors as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b0696b9",
      "metadata": {
        "id": "5b0696b9"
      },
      "outputs": [],
      "source": [
        "class CoreModelWrapper(torch.nn.Module):\n",
        "    def __init__(self, core_model, output_idxs):\n",
        "        super().__init__()\n",
        "        self.core = core_model\n",
        "        self.idxs = output_idxs\n",
        "        \n",
        "    def forward(self, *args, **kwargs):\n",
        "        x = self.core(*args, **kwargs)\n",
        "        return tuple(x if j == -1 else self.core.last_y[j] for j in self.idxs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeec4c1a",
      "metadata": {
        "id": "aeec4c1a"
      },
      "outputs": [],
      "source": [
        "list_of_layers = list(core_model.model.children())\n",
        "last_layer = list_of_layers.pop(-1)\n",
        "\n",
        "core_model.model = torch.nn.Sequential(*list_of_layers)\n",
        "core_wrapper = CoreModelWrapper(core_model, last_layer.f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332cbc38",
      "metadata": {
        "id": "332cbc38"
      },
      "source": [
        "Now we are ready for optimizing the body of YOLOv5 using the `Speedster` function `optimize_model`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d1fc4d01",
      "metadata": {
        "id": "d1fc4d01"
      },
      "source": [
        "Speedster was built to be very easy to use. To optimize a model, you only need to specify the model, the batch size and input size for each input tensor, and a directory in which to save the optimized model. In the example, we chose the same directory in which this notebook runs.\n",
        "\n",
        "With the latest API, there are two ways to use Speedster:\n",
        "\n",
        "- Option A: Accelerate the model up to ~10 times without losing in performances (accuracy/precision/etc.)\n",
        "- Option B: Accelerate the model up to ~30 times with a pre-defined maximum loss in performances\n",
        "    \n",
        "To learn more about how to use Speedster, check out the <a href=\"https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster#-speedster\" target=\"_blank\" style=\"text-decoration: none;\"> readme on GitHub </a>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb07403",
      "metadata": {
        "id": "ceb07403"
      },
      "source": [
        "In this example, we provide the code to run option B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c15b09",
      "metadata": {
        "id": "20c15b09"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fcf6332",
      "metadata": {
        "id": "8fcf6332"
      },
      "outputs": [],
      "source": [
        "img_name = \"zidane.png\"\n",
        "Image.open(requests.get(imgs[0], stream=True).raw).save(img_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "178a31f1",
      "metadata": {
        "id": "178a31f1"
      },
      "outputs": [],
      "source": [
        "def read_and_crop(im, original_model, img_size):\n",
        "    p  =  next(original_model.parameters())\n",
        "    im = Image.open(requests.get(im, stream=True).raw if str(im).startswith('http') else im)\n",
        "    max_y, max_x = im.size\n",
        "    ptr_x = np.random.choice(max_x-img_size[0])\n",
        "    ptr_y = np.random.choice(max_y-img_size[1])\n",
        "    im = np.array(im.crop((ptr_y, ptr_x, ptr_y + img_size[1], ptr_x + img_size[0])))\n",
        "    x = np.expand_dims(im, axis=0)\n",
        "    x = np.ascontiguousarray(np.array(x).transpose((0, 3, 1, 2)))  # stack and BHWC to BCHW\n",
        "    x = torch.from_numpy(x).to(p.device).type_as(p) / 255  # uint8 to fp16/32\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51757959",
      "metadata": {
        "id": "51757959"
      },
      "outputs": [],
      "source": [
        "input_data = [((read_and_crop(img_name, core_model, (384, 640)),), None) for _ in range(500)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c01adfeb",
      "metadata": {
        "id": "c01adfeb"
      },
      "outputs": [],
      "source": [
        "model_optimized = optimize_model(\n",
        "    model=core_wrapper,\n",
        "    input_data=input_data,\n",
        "    optimization_time=\"unconstrained\",\n",
        "    metric_drop_ths=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e2866c",
      "metadata": {
        "id": "78e2866c"
      },
      "source": [
        "Now let's regroup together the optimized body and the head of YOLO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff75e85f",
      "metadata": {
        "id": "ff75e85f"
      },
      "outputs": [],
      "source": [
        "class OptimizedYolo(torch.nn.Module):\n",
        "    def __init__(self, optimized_core, head_layer):\n",
        "        super().__init__()\n",
        "        self.core = optimized_core\n",
        "        self.head = head_layer\n",
        "    \n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        x = list(self.core(x)) # it's a tuple\n",
        "        return self.head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f973f2",
      "metadata": {
        "id": "c0f973f2"
      },
      "outputs": [],
      "source": [
        "final_core = OptimizedYolo(model_optimized, last_layer)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "495c1642",
      "metadata": {},
      "source": [
        "Let's compare the original model performance with the optimized one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e39d5b",
      "metadata": {
        "id": "82e39d5b"
      },
      "outputs": [],
      "source": [
        "from nebullvm.tools.benchmark import benchmark\n",
        "\n",
        "original_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=True)\n",
        "original_core = original_model.model.model\n",
        "\n",
        "print(\"Benchmark original model\")\n",
        "benchmark(original_core, input_data)\n",
        "\n",
        "print(\"Benchmark optimized model\")\n",
        "benchmark(final_core, input_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cd04f365",
      "metadata": {},
      "source": [
        "We can finally change the original model with the optimized one in the original model object, and make sure that it works properly by performing a prediction on the sample image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72a0cc9",
      "metadata": {
        "id": "b72a0cc9"
      },
      "outputs": [],
      "source": [
        "model.model.model = final_core\n",
        "results = model(imgs)\n",
        "results.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b72bdf54",
      "metadata": {},
      "source": [
        "## Save and reload the optimized model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ada71f91",
      "metadata": {},
      "source": [
        "We can easily save to disk the optimized model with the following line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99b3a9d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "save_model(model_optimized, \"model_save_path\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6308ddd7",
      "metadata": {},
      "source": [
        "We can then load again the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9946f6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_optimized = load_model(\"model_save_path\")\n",
        "final_core = OptimizedYolo(model_optimized, last_layer)\n",
        "model.model.model = final_core"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50807de",
      "metadata": {
        "id": "d50807de"
      },
      "source": [
        "What an amazing result, right?!? Stay tuned for more cool content from the Nebuly team :) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b77ff2ac",
      "metadata": {
        "id": "b77ff2ac"
      },
      "source": [
        "<center> \n",
        "    <a href=\"https://discord.com/invite/RbeQMu886J\" target=\"_blank\" style=\"text-decoration: none;\"> Join the community </a> |\n",
        "    <a href=\"https://nebuly.gitbook.io/nebuly/welcome/questions-and-contributions\" target=\"_blank\" style=\"text-decoration: none;\"> Contribute to the library </a>\n",
        "</center>\n",
        "\n",
        "<center> \n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster#key-concepts\" target=\"_blank\" style=\"text-decoration: none;\"> How speedster works </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster#documentation\" target=\"_blank\" style=\"text-decoration: none;\"> Documentation </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster#quick-start\" target=\"_blank\" style=\"text-decoration: none;\"> Quick start </a> \n",
        "</center>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ecf6a6cfad64af698a88479ba95005b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_682cafb37aa34c75961d61d2665a50b7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5e71284dc02f4346b217732643c90b86",
            "value": "100%"
          }
        },
        "56a1b99b282a4a63a64f48347963a5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e71284dc02f4346b217732643c90b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65786546f69b420b9ec8451c97338f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "682cafb37aa34c75961d61d2665a50b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f41159d22fe4ce7b8e7789a92478242": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ecf6a6cfad64af698a88479ba95005b",
              "IPY_MODEL_e7a2646ac0cd4afba67823799147ce13",
              "IPY_MODEL_fd77306783b84b489b90d072a44a27d8"
            ],
            "layout": "IPY_MODEL_94a4bc5454074b5c900186a60a950d19"
          }
        },
        "881f619ee75547a49c6d48fd3140721c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a4bc5454074b5c900186a60a950d19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59557bb103e4a3b96062c60d539db35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a2646ac0cd4afba67823799147ce13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881f619ee75547a49c6d48fd3140721c",
            "max": 14808437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56a1b99b282a4a63a64f48347963a5ab",
            "value": 14808437
          }
        },
        "fd77306783b84b489b90d072a44a27d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59557bb103e4a3b96062c60d539db35",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_65786546f69b420b9ec8451c97338f30",
            "value": " 14.1M/14.1M [00:00&lt;00:00, 24.5MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
