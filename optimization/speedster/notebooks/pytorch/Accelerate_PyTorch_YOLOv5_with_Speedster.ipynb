{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c977e4a",
      "metadata": {
        "id": "3c977e4a"
      },
      "source": [
        "![nebullvm nebuly AI accelerate inference optimize DeepLearning](https://user-images.githubusercontent.com/38586138/201391643-a80407e5-2c28-409c-90c9-327795cd27e8.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6240f0ea",
      "metadata": {
        "id": "6240f0ea"
      },
      "source": [
        "# Accelerate PyTorch YOLOv5 with Speedster\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cfcd562",
      "metadata": {
        "id": "6cfcd562"
      },
      "source": [
        "Hi and welcome ðŸ‘‹\n",
        "\n",
        "In this notebook we will discover how in just a few steps you can speed up the response time of deep learning model inference using the Speedster app from the open-source library nebullvm.\n",
        "\n",
        "With Speedster's latest API, you can speed up models up to 10 times without any loss of accuracy (option A), or accelerate them up to 20-30 times by setting a self-defined amount of accuracy/precision that you are willing to trade off to get even lower response time (option B). To accelerate your model, Speedster takes advantage of various optimization techniques such as deep learning compilers (in both option A and option B), quantization, half accuracy, and so on (option B).\n",
        "\n",
        "Let's jump to the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38171e92",
      "metadata": {},
      "outputs": [],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "okgu97ThVwnH",
      "metadata": {
        "id": "okgu97ThVwnH"
      },
      "source": [
        "### Install Speedster"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48aljCHu14-H",
      "metadata": {
        "id": "48aljCHu14-H"
      },
      "source": [
        "Install Speedster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QFQh3BVr1-GO",
      "metadata": {
        "id": "QFQh3BVr1-GO"
      },
      "outputs": [],
      "source": [
        "!pip install speedster"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a7a86b3",
      "metadata": {
        "id": "8a7a86b3"
      },
      "source": [
        "Install deep learning compilers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffbfa32",
      "metadata": {
        "id": "cffbfa32"
      },
      "outputs": [],
      "source": [
        "!python -m nebullvm.installers.auto_installer --frameworks torch --compilers all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62f5afa",
      "metadata": {
        "id": "e62f5afa"
      },
      "source": [
        "### Install and test YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38d727d",
      "metadata": {
        "id": "b38d727d"
      },
      "source": [
        "Let's install YOLO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48f6a35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f48f6a35",
        "outputId": "5b06307a-9196-4e5e-a542-1254d6c94ce2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "! pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "92f49833",
      "metadata": {
        "id": "92f49833"
      },
      "source": [
        "We start by downloading the model from the Torch hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc46f67",
      "metadata": {
        "id": "2dc46f67"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "import types\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead6637d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248,
          "referenced_widgets": [
            "7f41159d22fe4ce7b8e7789a92478242",
            "2ecf6a6cfad64af698a88479ba95005b",
            "e7a2646ac0cd4afba67823799147ce13",
            "fd77306783b84b489b90d072a44a27d8",
            "94a4bc5454074b5c900186a60a950d19",
            "682cafb37aa34c75961d61d2665a50b7",
            "5e71284dc02f4346b217732643c90b86",
            "881f619ee75547a49c6d48fd3140721c",
            "56a1b99b282a4a63a64f48347963a5ab",
            "a59557bb103e4a3b96062c60d539db35",
            "65786546f69b420b9ec8451c97338f30"
          ]
        },
        "id": "ead6637d",
        "outputId": "8d44d380-535d-446c-fcb0-bb55ba9e9f84"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KcteQ5tsWy1v",
      "metadata": {
        "id": "KcteQ5tsWy1v"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d07ab0",
      "metadata": {
        "id": "37d07ab0"
      },
      "source": [
        "## Optimization with Speedster"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332cbc38",
      "metadata": {
        "id": "332cbc38"
      },
      "source": [
        "Now we are ready for optimizing the body of YOLOv5 using the `Speedster` function `optimize_model`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d1fc4d01",
      "metadata": {
        "id": "d1fc4d01"
      },
      "source": [
        "Speedster was built to be very easy to use. To optimize a model, you only need to specify the model, the batch size and input size for each input tensor, and a directory in which to save the optimized model. In the example, we chose the same directory in which this notebook runs.\n",
        "\n",
        "With the latest API, there are two ways to use Speedster:\n",
        "\n",
        "- Option A: Accelerate the model up to ~10 times without losing in performances (accuracy/precision/etc.)\n",
        "- Option B: Accelerate the model up to ~30 times with a pre-defined maximum loss in performances\n",
        "    \n",
        "To learn more about how to use Speedster, check out the <a href=\"https://github.com/nebuly-ai/nebuly/tree/main/optimization/speedster#-speedster\" target=\"_blank\" style=\"text-decoration: none;\"> readme on GitHub </a>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb07403",
      "metadata": {
        "id": "ceb07403"
      },
      "source": [
        "In this example, we provide the code to run option B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f9f650",
      "metadata": {
        "id": "74f9f650"
      },
      "outputs": [],
      "source": [
        "from speedster import optimize_model, save_model, load_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b729ccce",
      "metadata": {},
      "source": [
        "Let's load some example data to feed the optimize_model function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c15b09",
      "metadata": {
        "id": "20c15b09"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fcf6332",
      "metadata": {
        "id": "8fcf6332"
      },
      "outputs": [],
      "source": [
        "img_name = \"zidane.png\"\n",
        "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images\n",
        "Image.open(requests.get(imgs[0], stream=True).raw).save(img_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "178a31f1",
      "metadata": {
        "id": "178a31f1"
      },
      "outputs": [],
      "source": [
        "def read_and_crop(im, original_model, img_size):\n",
        "    p  =  next(original_model.parameters())\n",
        "    im = Image.open(requests.get(im, stream=True).raw if str(im).startswith('http') else im)\n",
        "    max_y, max_x = im.size\n",
        "    ptr_x = np.random.choice(max_x-img_size[0])\n",
        "    ptr_y = np.random.choice(max_y-img_size[1])\n",
        "    im = np.array(im.crop((ptr_y, ptr_x, ptr_y + img_size[1], ptr_x + img_size[0])))\n",
        "    x = np.expand_dims(im, axis=0)\n",
        "    x = np.ascontiguousarray(np.array(x).transpose((0, 3, 1, 2)))  # stack and BHWC to BCHW\n",
        "    x = torch.from_numpy(x).to(p.device).type_as(p) / 255  # uint8 to fp16/32\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51757959",
      "metadata": {
        "id": "51757959"
      },
      "outputs": [],
      "source": [
        "input_data = [((read_and_crop(img_name, model, (640, 640)),), None) for _ in range(100)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c01adfeb",
      "metadata": {
        "id": "c01adfeb"
      },
      "outputs": [],
      "source": [
        "model_optimized = optimize_model(\n",
        "    model=model,\n",
        "    input_data=input_data,\n",
        "    optimization_time=\"unconstrained\",\n",
        "    metric_drop_ths=0.05\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "495c1642",
      "metadata": {},
      "source": [
        "Let's compare the original model performance with the optimized one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e39d5b",
      "metadata": {
        "id": "82e39d5b"
      },
      "outputs": [],
      "source": [
        "from nebullvm.tools.benchmark import benchmark\n",
        "\n",
        "original_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=True)\n",
        "print(\"Benchmark original model\")\n",
        "benchmark(original_model, input_data)\n",
        "\n",
        "print(\"Benchmark optimized model\")\n",
        "benchmark(model_optimized, input_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f0d6d006",
      "metadata": {},
      "source": [
        "Let's ensure that the output of the original model is the same as the optimized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c0dbab",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_tensor = torch.randn(1, 3, 640, 640).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfe573fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "model(input_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89654058",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_optimized(input_tensor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b72bdf54",
      "metadata": {},
      "source": [
        "## Save and reload the optimized model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ada71f91",
      "metadata": {},
      "source": [
        "We can easily save to disk the optimized model with the following line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99b3a9d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "save_model(model_optimized, \"model_save_path\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6308ddd7",
      "metadata": {},
      "source": [
        "We can then load again the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9946f6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_optimized = load_model(\"model_save_path\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50807de",
      "metadata": {
        "id": "d50807de"
      },
      "source": [
        "What an amazing result, right?!? Stay tuned for more cool content from the Nebuly team :) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b77ff2ac",
      "metadata": {
        "id": "b77ff2ac"
      },
      "source": [
        "<center> \n",
        "    <a href=\"https://discord.com/invite/RbeQMu886J\" target=\"_blank\" style=\"text-decoration: none;\"> Join the community </a> |\n",
        "    <a href=\"https://nebuly.gitbook.io/nebuly/welcome/questions-and-contributions\" target=\"_blank\" style=\"text-decoration: none;\"> Contribute to the library </a>\n",
        "</center>\n",
        "\n",
        "<center> \n",
        "    <a href=\"https://github.com/nebuly-ai/nebuly/tree/main/optimization/speedster#key-concepts\" target=\"_blank\" style=\"text-decoration: none;\"> How speedster works </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebuly/tree/main/optimization/speedster#documentation\" target=\"_blank\" style=\"text-decoration: none;\"> Documentation </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebuly/tree/main/optimization/speedster#quick-start\" target=\"_blank\" style=\"text-decoration: none;\"> Quick start </a> \n",
        "</center>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (main, Aug 30 2022, 04:58:14) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ecf6a6cfad64af698a88479ba95005b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_682cafb37aa34c75961d61d2665a50b7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5e71284dc02f4346b217732643c90b86",
            "value": "100%"
          }
        },
        "56a1b99b282a4a63a64f48347963a5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e71284dc02f4346b217732643c90b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65786546f69b420b9ec8451c97338f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "682cafb37aa34c75961d61d2665a50b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f41159d22fe4ce7b8e7789a92478242": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ecf6a6cfad64af698a88479ba95005b",
              "IPY_MODEL_e7a2646ac0cd4afba67823799147ce13",
              "IPY_MODEL_fd77306783b84b489b90d072a44a27d8"
            ],
            "layout": "IPY_MODEL_94a4bc5454074b5c900186a60a950d19"
          }
        },
        "881f619ee75547a49c6d48fd3140721c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a4bc5454074b5c900186a60a950d19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59557bb103e4a3b96062c60d539db35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a2646ac0cd4afba67823799147ce13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881f619ee75547a49c6d48fd3140721c",
            "max": 14808437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56a1b99b282a4a63a64f48347963a5ab",
            "value": 14808437
          }
        },
        "fd77306783b84b489b90d072a44a27d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59557bb103e4a3b96062c60d539db35",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_65786546f69b420b9ec8451c97338f30",
            "value": " 14.1M/14.1M [00:00&lt;00:00, 24.5MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
